Short answer: keep the habit, change the medium, add projects and metrics.

# Keep

* Daily Python + NumPy.
* Daily coding questions.

# Fix

* **Notes**: move from Google Docs to a public Git repo. Use Jupyter notebooks + markdown. One folder per topic. Commit daily.
* **Depth**: one topic every **2 days** with code+tests, not one/day with summaries.
* **AI use**: read official docs first, then ask AI for gaps. Verify with unit tests.

# Add

* **Projects track**: build 1 tiny app and 1 tiny ML service in 3–4 weeks.

  * App: FastAPI + Postgres CRUD, JWT, 10–15 tests, Docker, deploy.
  * ML: pandas + scikit-learn, metrics table, `/predict` endpoint, tests.
* **Testing**: pytest + ruff + mypy on every repo. Target ≥85% coverage.
* **Problem mix**: 2 timed LeetCode **mediums** per day (arrays/strings/hash maps → two pointers → binary search → trees/graphs → DP).
* **Retrieval**: spaced repetition for syntax/APIs in Anki. 10–15 reviews/day.
* **Weekly mock**: 1 timed 45–60 min interview. Record and review.

# Weekly cadence

* Mon–Tue: one topic deep dive + notebook + tests.
* Wed–Thu: project feature work.
* Fri: 2–4 OAs or timed sets, refactor, write README notes.
* Sat: ship something: deploy, demo GIF, or blog note.
* Sun: mock interview + plan next week.

# Metrics (non-negotiable)

* 10 commits/week across study+projects.
* 14 timed mediums/week with score notes.
* Two PRs merged (your repos or OSS) per month.
* One shipped artifact/week (endpoint, notebook, metric chart, or demo).

# Exit criteria for “ready to apply hard”

* Two live links with tests and READMEs.
* ≥100 timed mediums completed with notes.
* You can explain broadcasting, views vs copies, vectorization, and Big-O for your project endpoints without prompts.

If you want, I’ll generate a repo scaffold (FastAPI + Postgres + tests + CI) and a NumPy notebook template today.
